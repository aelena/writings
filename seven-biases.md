Originally published on LinkedIn [here](https://www.linkedin.com/pulse/seven-biases-can-kill-your-project-antonio-elena-0c4yf)

___

There are a series of well-documented biases that we consistently engage in that prevent teams from asking - or even contemplating - the reasons why their projects can, and perhaps will, fail. Being familiar with those common biases, acknowledging they will inevitably creep in and actively working to mitigate them is crucial for keeping a project on track. Most of them have a degree of overlap.


__1. Optimism Bias__
Optimism bias refers to the tendency of project managers and teams to overestimate the likelihood of positive outcomes while underestimating potential risks and potential or likely roadblocks. And not only risks or setbacks for which we are therefore unprepared, we also tend to understimate effort, durations (ambitious timelines / unrealistic deadlines anyone?), estimations and difficulties. Simply put, our brain tends to sideline and ignore bad things. Ask yourself and your team a simple but powerful question, "Why will this project fail?" 

When optimism bias prevails, teams tend to overlook critical warning signs or fail to conduct thorough risk assessments, leading to unanticipated roadblocks. To combat this bias, it's essential to foster a culture of realism, where risks are openly discussed, and contingency plans are developed. 

I've been sometimes "accused" in the past of being too pessimistic for being realistic about serious risks and not wanting to bask in optimism and positive outlooks that I thought were not completely justified, so you want to not appear as too negative or appear as if wanting to block the project so you need to support your point with solid arguments. In any case, regularly revisit your assumptions. Sharing with external reviewers can also provide different perspectives outside your project's bubble.

<br/>

__2. Confirmation Bias__
Confirmation bias occurs when project teams favor information that confirms their pre-existing hypothesis, beliefs or decisions (the decision made bias), while discounting or ignoring evidence that contradicts them. This bias can be particularly dangerous during the planning and execution phases, where selective attention to data can result in flawed decision-making. For example, a team might continue with a strategy that initial data suggests is ineffective simply because they are emotionally or intellectually committed to it - the idea of emotional investment. 

A classic anti-pattern is the "we've always done like this" here. Unfortunately, in our society it is increasingly common that in the face of cognitive dissonance, we don't reevaluate our assumptions and beliefs, rather we cocoon ourselves into our existing position and reject the contradicting evidence. The more solid and fact-based it is, the more people tend to assume a defensive position, especially if there is a political or ideologic angle to the project, or the investment and the need to save face is already quite strong. 

Safeguarding existing constituencies in large organizations is another political reason why this happens. To avoid this pitfall, it's important to encourage a culture of critical thinking, where dissenting opinions are valued and decisions are based on comprehensive, unbiased data analysis. Make sure you are not only picking the signal you prefer from the noise.

<br/>


__3. Self-Serving Bias__
Self-serving bias is the tendency to attribute positive outcomes to one's own actions, efforts and skill while blaming negative outcomes on external factors. We overestimate the former while understimating the latter. 

In fact, we might have already overlooked and underestimated those external factors by virtue of the optimism bias. This bias plays a part in creating a toxic environment where accountability is deflected, and learning opportunities are missed. Team members might downplay their own mistakes, attributing them to external circumstances, which can prevent the team from accurately diagnosing issues and making necessary adjustments. To counteract self-serving bias, it's vital to promote a culture of accountability, where successes and failures are objectively analyzed, and lessons learnt are shared openly.

<br/>


__4. Sunk-Cost Fallacy__
The sunk-cost fallacy involves continuing a project or course of action based on the cumulative prior investment made in time, money, effort rather than assessing current and future prospects in the face of new data. This bias can trap project teams into persisting with failing initiatives simply because they have already invested heavily in them. The danger here is that resources continue to be funneled into a project that no longer has a viable path to success or has very low chances, leading to eventual greater losses (normally when that eventually happens, everyone looks to the side and avoid discussing the topic and extract the costly lesson learnt). 

This bias is why it's critical to regularly reassess the project's value proposition and be willing to pivot - like many startups have traditionally done - or terminate the project, regardless of past investments. This is a bias that affect individual investors holding on to stocks that will never regain those high valuations of the past. 

<br/>


__5. Groupthink Bias__
Groupthink occurs when the desire for harmony and consensus within a team leads to irrational or dysfunctional decision-making and to no one thinking out loud or pondering why this project does not make sense or will fail. In an environment where groupthink prevails, critical thinking is suppressed, and dissenting views are often silenced. This can result in the team collectively moving forward sticking to suboptimal or risky decisions without wanting to consider other options or the potential downsides. 

Groupthink is a feature or tell-tale sign of a defective culture in an organization, and in some cases can actually be influenced by outside hype and the desire to jump into a specific trend or bandwagon. To mitigate groupthink, it's crucial to create an environment where diverse opinions are encouraged (and heard) and team members feel safe to voice concerns. Appointing a "devil's advocate" or conducting anonymous surveys can also help surface alternative viewpoints that might otherwise be overlooked.

<br/>


__6. Emotional Investment Bias__
Emotional investment bias occurs when personal attachment to a project, idea, or decision clouds one's thinking and judgement, making it difficult to evaluate the situation objectively. Project leaders and team members may become so emotionally invested in a particular decision, course of action or expected outcome that they ignore signs that it may not be the best course of action, again that refusal to reevaluate one's thinking in the face of cognitive dissonance. 

This bias can lead to insisting in ineffective strategies and a reluctance to adapt to changing circumstances. To manage emotional investment bias, cultivate a mindset of flexibility and detachment, kill that project, delete that code, stop that investment and so on. Encouraging regular feedback loops and bringing in external perspectives can help maintain objectivity and ensure decisions are made based on logic rather than emotion.

<br/>


__7. Anchoring Bias__
Anchoring bias is the tendency to rely too heavily on the first piece of information encountered (the "anchor") when making decisions. In project management, this can occur when initial estimates or assumptions disproportionately influence subsequent decisions, even when new, contradictory information becomes available. It is well known how an estimation obtained at gun-point with no data at all becomes set in stone forever and has the binding force of a biblical covenant. An initial budget estimate might anchor the team's perception of project costs, leading them to underestimate expenses later on. To combat anchoring bias, it's important to approach project estimates and assumptions with flexibility, regularly revisiting and adjusting them as new information arises. Encouraging a culture where initial assumptions are challenged can also help prevent this bias from taking hold.

<br/>


__8. Bonus bias. Kick the ball forward.__
which shows in sentences such as "We will deal with this later" / "...at the end of the project" / "we'll see to that when it comes up" and variations thereof. This bias is the tendency to postpone addressing thorny issues and making difficult decisions, often with the hope that circumstances will improve by themselves or that the problem will resolve itself over time - which sometimes happens too. 

This bias can manifest itself due to multiple reasons that can easily compound over time such as being already overloaded with other problems and pending decisions, which only accentuates the issue, the fact that lack data or knowledge to make a decision now, our inability to foresee the ramifications or dependencies, increased general complexity of the environment (increasing inability to cope, insecurity and despair) or indeterminate political reasons only known to a few (and therefore will rarely be aired).

<br/>


__Conclusion__
Biases are an inherent part of human decision-making, but they will have serious for any project consequences when left unchecked and unmanaged. By understanding these biases project managers can take proactive steps to mitigate their effects. Perhaps a good moment to revisit these biases is at the end of each sprint, most likely booking some time to reflect on them as part of the self-examination in the retrospective and keep an eye on them raising their heads in the project. Cultivating a culture of openness, accountability, and critical thinking within the team can help ensure that decisions are made based on objective analysis rather than cognitive bias. In doing so, you'll greatly increase the likelihood of your project's success.
